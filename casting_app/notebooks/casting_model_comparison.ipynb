{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ¥‡ ì£¼ì¡° ê²°í•¨ ê²€ì‚¬: 4ëŒ€ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (Kaggle ì „ìš© í†µí•©ë³¸)\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ **ì™¸ë¶€ íŒŒì¼(src í´ë” ë“±) ì—†ì´ë„** ì´ íŒŒì¼ í•˜ë‚˜ë§Œìœ¼ë¡œ 4ê°€ì§€ ëª¨ë¸(**ResNet18, DenseNet121, EfficientNet-B0, MobileNetV2**)ì„ í•™ìŠµí•˜ê³  ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ëª¨ë“  ì½”ë“œë¥¼ í†µí•©í–ˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ“Œ ì‘ì—… í™˜ê²½ ì„¤ì •\n",
                "1. **Accelerator**: GPU P100 (ê¶Œì¥)\n",
                "2. **Internet**: ON\n",
                "3. **Dataset**: `Casting Product Image Data`ê°€ ì¶”ê°€ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
                "\n",
                "### ğŸ“ ê²°ê³¼ë¬¼ ìœ„ì¹˜\n",
                "ëª¨ë“  ê²°ê³¼ë¬¼(ê·¸ë˜í”„, ëª¨ë¸ íŒŒì¼)ì€ **`/kaggle/working`** ì— ë°”ë¡œ ì €ì¥ë˜ì–´ ìš°ì¸¡ Output íƒ­ì—ì„œ ì¦‰ì‹œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from tqdm.auto import tqdm\n",
                "from PIL import Image\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import models, transforms\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "\n",
                "# --- [1. ì „ì—­ ì„¤ì •] ---\n",
                "# ìºê¸€ ë°ì´í„°ì…‹ ê²½ë¡œ (ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì ˆë  ìˆ˜ ìˆìŒ)\n",
                "DATA_DIR = \"/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data\"\n",
                "OUTPUT_DIR = Path(\"/kaggle/working\")\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 5  # ì›í•˜ì‹œëŠ” ëŒ€ë¡œ ì¡°ì ˆ ê°€ëŠ¥\n",
                "LR = 0.001\n",
                "\n",
                "print(f\"âœ… Device: {DEVICE}\")\n",
                "print(f\"âœ… Data Path: {DATA_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [2. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜] ---\n",
                "class CastingDataset(Dataset):\n",
                "    def __init__(self, root_dir, transform=None):\n",
                "        self.root_dir = Path(root_dir)\n",
                "        self.transform = transform\n",
                "        self.classes = ['ok_front', 'def_front']\n",
                "        self.image_paths = []\n",
                "        self.labels = []\n",
                "        \n",
                "        for i, cls in enumerate(self.classes):\n",
                "            cls_path = self.root_dir / cls\n",
                "            # jpegì™€ jpg ëª¨ë‘ ì§€ì›\n",
                "            exts = ['*.jpeg', '*.jpg', '*.png']\n",
                "            for ext in exts:\n",
                "                for img_path in cls_path.glob(ext):\n",
                "                    self.image_paths.append(img_path)\n",
                "                    self.labels.append(i)\n",
                "                    \n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
                "        label = self.labels[idx]\n",
                "        if self.transform:\n",
                "            img = self.transform(img)\n",
                "        return img, label\n",
                "\n",
                "# ë°ì´í„° ë³€í™˜ (Augmentation í¬í•¨)\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(p=0.5),\n",
                "    transforms.RandomVerticalFlip(p=0.5),    # ìƒí•˜ ë°˜ì „ (New)\n",
                "    transforms.RandomRotation(45),           # íšŒì „ 45ë„ (Stronger)\n",
                "    transforms.ColorJitter(brightness=0.3, contrast=0.3), # ë°ê¸°/ëŒ€ë¹„ ë³€í™” (New)\n",
                "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), # ì´ë™/ìŠ¤ì¼€ì¼ (New)\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "])\n",
                "\n",
                "test_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# ë¡œë” ìƒì„±\n",
                "train_set = CastingDataset(os.path.join(DATA_DIR, \"train\"), transform=train_transform)\n",
                "test_set = CastingDataset(os.path.join(DATA_DIR, \"test\"), transform=test_transform)\n",
                "\n",
                "# num_workersë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ í”„ë¡œì„¸ìŠ¤ ì¶©ëŒ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
                "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
                "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
                "\n",
                "print(f\"ğŸ“¦ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: Train({len(train_set)}), Test({len(test_set)})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [3. 4ê°€ì§€ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜] ---\n",
                "def build_model(model_name):\n",
                "    print(f\"ğŸ› ï¸ Building {model_name}...\")\n",
                "    if model_name == 'resnet18':\n",
                "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
                "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
                "    elif model_name == 'densenet121':\n",
                "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
                "        model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
                "    elif model_name == 'efficientnet_b0':\n",
                "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
                "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
                "    elif model_name == 'mobilenet_v2':\n",
                "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
                "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
                "    return model.to(DEVICE)\n",
                "\n",
                "print(\"âœ… ëª¨ë¸ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [4. í•™ìŠµ í”„ë¡œí† ì½œ ì •ì˜] ---\n",
                "def run_training(model_name, model, train_loader, test_loader):\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
                "    \n",
                "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "    best_acc = 0.0\n",
                "    \n",
                "    for epoch in range(EPOCHS):\n",
                "        # Training Phase\n",
                "        model.train()\n",
                "        running_loss, correct, total = 0.0, 0, 0\n",
                "        \n",
                "        pbar = tqdm(train_loader, desc=f\"[{model_name}] Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
                "        for imgs, labels in pbar:\n",
                "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(imgs)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            running_loss += loss.item() * imgs.size(0)\n",
                "            _, preds = torch.max(outputs, 1)\n",
                "            correct += torch.sum(preds == labels.data)\n",
                "            total += labels.size(0)\n",
                "            \n",
                "        epoch_loss = running_loss / total\n",
                "        epoch_acc = correct.double() / total\n",
                "        \n",
                "        # Test/Validation Phase\n",
                "        model.eval()\n",
                "        current_val_loss, val_correct, val_total = 0.0, 0, 0\n",
                "        current_val_probs = []\n",
                "        current_val_labels = []\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for imgs, labels in test_loader:\n",
                "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
                "                outputs = model(imgs)\n",
                "                loss = criterion(outputs, labels)\n",
                "                current_val_loss += loss.item() * imgs.size(0)\n",
                "                \n",
                "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
                "                _, preds = torch.max(outputs, 1)\n",
                "                val_correct += torch.sum(preds == labels.data)\n",
                "                val_total += labels.size(0)\n",
                "                \n",
                "                current_val_probs.extend(probs.cpu().numpy())\n",
                "                current_val_labels.extend(labels.cpu().numpy())\n",
                "\n",
                "        v_loss = current_val_loss / val_total\n",
                "        v_acc = val_correct.double() / val_total\n",
                "        \n",
                "        history['train_loss'].append(epoch_loss)\n",
                "        history['train_acc'].append(epoch_acc.item())\n",
                "        history['val_loss'].append(v_loss)\n",
                "        history['val_acc'].append(v_acc.item())\n",
                "        \n",
                "        print(f\"Epoch {epoch+1}: Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f} | Val Acc: {v_acc:.4f} | Val Loss: {v_loss:.4f}\")\n",
                "        \n",
                "        # ëª¨ë¸ ì €ì¥\n",
                "        if v_acc > best_acc:\n",
                "            best_acc = v_acc\n",
                "            torch.save(model.state_dict(), OUTPUT_DIR / f\"{model_name}_best.pth\")\n",
                "            # ROC ê³„ì‚°ì„ ìœ„í•´ ìµœê³  ì„±ëŠ¥ì¼ ë•Œì˜ í™•ë¥ ê³¼ ë¼ë²¨ ì €ì¥\n",
                "            history['best_val_probs'] = current_val_probs\n",
                "            history['best_val_labels'] = current_val_labels\n",
                "            \n",
                "    return history\n",
                "\n",
                "print(\"âœ… í•™ìŠµ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [5. ì‹¤ì œ ë¹„êµ í•™ìŠµ ì‹¤í–‰] ---\n",
                "models_list = ['resnet18', 'densenet121', 'efficientnet_b0', 'mobilenet_v2']\n",
                "results = {}\n",
                "\n",
                "for name in models_list:\n",
                "    m = build_model(name)\n",
                "    results[name] = run_training(name, m, train_loader, test_loader)\n",
                "    print(f\"â­ {name} ì™„ë£Œ!\")\n",
                "\n",
                "print(\"\\nğŸŠ ëª¨ë“  ì‹¤í—˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [6. ìµœì¢… ê²°ê³¼ ì‹œê°í™”] ---\n",
                "fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
                "\n",
                "# 1. Accuracy Comparison\n",
                "for name, hist in results.items():\n",
                "    axes[0].plot(hist['val_acc'], label=f\"{name} (Best: {max(hist['val_acc']):.4f})\")\n",
                "axes[0].set_title(\"Model Comparison - Validation Accuracy\", fontsize=14)\n",
                "axes[0].set_xlabel(\"Epochs\")\n",
                "axes[0].set_ylabel(\"Accuracy\")\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, linestyle='--')\n",
                "\n",
                "# 2. Loss Comparison\n",
                "for name, hist in results.items():\n",
                "    axes[1].plot(hist['val_loss'], label=f\"{name} (Min: {min(hist['val_loss']):.4f})\")\n",
                "axes[1].set_title(\"Model Comparison - Validation Loss\", fontsize=14)\n",
                "axes[1].set_xlabel(\"Epochs\")\n",
                "axes[1].set_ylabel(\"Loss\")\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, linestyle='--')\n",
                "\n",
                "# 3. ROC Curve Comparison (Best Model State)\n",
                "for name, hist in results.items():\n",
                "    if 'best_val_labels' in hist:\n",
                "        fpr, tpr, _ = roc_curve(hist['best_val_labels'], hist['best_val_probs'])\n",
                "        roc_auc = auc(fpr, tpr)\n",
                "        axes[2].plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.4f})\")\n",
                "\n",
                "axes[2].plot([0, 1], [0, 1], 'k--', label='Random')\n",
                "axes[2].set_title(\"ROC Curve Comparison (Best Model)\", fontsize=14)\n",
                "axes[2].set_xlabel(\"False Positive Rate\")\n",
                "axes[2].set_ylabel(\"True Positive Rate\")\n",
                "axes[2].legend(loc='lower right')\n",
                "axes[2].grid(True, linestyle='--')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / \"model_performance_comparison.png\")\n",
                "plt.show()\n",
                "\n",
                "# ìš”ì•½ í…Œì´ë¸” ì¶œë ¥\n",
                "summary = []\n",
                "for name, hist in results.items():\n",
                "    summary.append({'Model': name, 'Best Acc': max(hist['val_acc']), 'Final Acc': hist['val_acc'][-1]})\n",
                "\n",
                "df_summary = pd.DataFrame(summary)\n",
                "df_summary.to_csv(OUTPUT_DIR / \"model_results.csv\", index=False)\n",
                "print(df_summary)\n",
                "\n",
                "print(f\"\\nğŸ’¾ ëª¨ë“  ê²°ê³¼ íŒŒì¼(.pth, .png, .csv)ì´ {OUTPUT_DIR} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [7. ìµœì¢… ìš°ìŠ¹ ëª¨ë¸(EfficientNet-B0) ì§‘ì¤‘ í•™ìŠµ] ---\n",
                "# 4ì¤‘ ì² ë²½ ë°©ì–´ (Dropout, Early Stopping, Checkpoint, Scheduler) ì ìš©\n",
                "\n",
                "# 1. ëª¨ë¸ ì¬ì •ì˜ (Dropout ì¶”ê°€)\n",
                "final_model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
                "\n",
                "# ê¸°ì¡´ Classifierì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë˜ Dropout ì¶”ê°€\n",
                "# EfficientNetì˜ classifierëŠ” ë³´í†µ [Dropout, Linear] êµ¬ì¡°ì„. ë” ê°•ë ¥í•˜ê²Œ ì„¤ì •.\n",
                "final_model.classifier = nn.Sequential(\n",
                "    nn.Dropout(p=0.5), # ê°•ë ¥í•œ Dropout (50%)\n",
                "    nn.Linear(1280, 2) # EfficientNet-B0ì˜ ë§ˆì§€ë§‰ ì±„ë„ì€ 1280\n",
                ")\n",
                "final_model = final_model.to(DEVICE)\n",
                "\n",
                "# 2. í•™ìŠµ ì„¤ì • (Scheduler & Early Stopping ì¤€ë¹„)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(final_model.parameters(), lr=0.0005) # ì¡°ê¸ˆ ë” ì‹ ì¤‘í•œ í•™ìŠµë¥ \n",
                "# ì„±ëŠ¥ì´ ì •ì²´ë˜ë©´ í•™ìŠµë¥ ì„ 1/10ë¡œ ì¤„ì„\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
                "\n",
                "# Early Stopping ì„¤ì •\n",
                "patience_limit = 5\n",
                "patience_check = 0\n",
                "best_loss = float('inf')\n",
                "\n",
                "print(\"ğŸš€ ìµœì¢… ëª¨ë¸(EfficientNet-B0) ì‹¬í™” í•™ìŠµ ì‹œì‘...\")\n",
                "\n",
                "FINAL_EPOCHS = 20 # ì¶©ë¶„íˆ ê¸¸ê²Œ ì¡ì§€ë§Œ Early Stoppingìœ¼ë¡œ ì¡°ê¸° ì¢…ë£Œë¨\n",
                "final_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(FINAL_EPOCHS):\n",
                "    # Train\n",
                "    final_model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for imgs, labels in train_loader:\n",
                "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = final_model(imgs)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item() * imgs.size(0)\n",
                "        _, preds = torch.max(outputs, 1)\n",
                "        correct += torch.sum(preds == labels.data)\n",
                "        total += labels.size(0)\n",
                "    \n",
                "    # Validation\n",
                "    final_model.eval()\n",
                "    val_loss = 0.0\n",
                "    val_correct = 0\n",
                "    val_total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for imgs, labels in test_loader:\n",
                "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
                "            outputs = final_model(imgs)\n",
                "            loss = criterion(outputs, labels)\n",
                "            val_loss += loss.item() * imgs.size(0)\n",
                "            _, preds = torch.max(outputs, 1)\n",
                "            val_correct += torch.sum(preds == labels.data)\n",
                "            val_total += labels.size(0)\n",
                "            \n",
                "    epoch_train_loss = running_loss / len(train_set)\n",
                "    epoch_val_loss = val_loss / val_total\n",
                "    epoch_train_acc = correct.double() / total\n",
                "    epoch_val_acc = val_correct.double() / val_total\n",
                "    \n",
                "    final_history['train_loss'].append(epoch_train_loss)\n",
                "    final_history['train_acc'].append(epoch_train_acc.item())\n",
                "    final_history['val_loss'].append(epoch_val_loss)\n",
                "    final_history['val_acc'].append(epoch_val_acc.item())\n",
                "    \n",
                "    print(f\"Epoch {epoch+1}: Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")\n",
                "    \n",
                "    # Scheduler Step\n",
                "    scheduler.step(epoch_val_loss)\n",
                "    \n",
                "    # Checkpoint & Early Stopping\n",
                "    if epoch_val_loss < best_loss:\n",
                "        best_loss = epoch_val_loss\n",
                "        patience_check = 0\n",
                "        torch.save(final_model.state_dict(), OUTPUT_DIR / \"final_efficientnet_b0.pth\")\n",
                "        print(f\"  âœ… Best Model Saved (Loss: {best_loss:.4f})\")\n",
                "    else:\n",
                "        patience_check += 1\n",
                "        print(f\"  âš ï¸ ì„±ëŠ¥ ê°œì„  ì—†ìŒ ({patience_check}/{patience_limit})\")\n",
                "        if patience_check >= patience_limit:\n",
                "            print(\"ğŸ›‘ Early Stopping ë°œë™! í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
                "            break\n",
                "\n",
                "print(\"ğŸ ìµœì¢… í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [7-1. ìµœì¢… í•™ìŠµ ê²°ê³¼ ì‹œê°í™”] ---\n",
                "# í•™ìŠµ ê³¼ì •ì—ì„œì˜ Lossì™€ Accuracy ë³€í™” ë³€í™”ë¥¼ ê·¸ë˜í”„ë¡œ í™•ì¸í•©ë‹ˆë‹¤.\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "plt.figure(figsize=(15, 6))\n",
                "\n",
                "# 1. Loss Curve\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(final_history['train_loss'], label='Train Loss', marker='.')\n",
                "plt.plot(final_history['val_loss'], label='Val Loss', marker='.')\n",
                "plt.title('Final Model Training - Loss')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True, linestyle='--')\n",
                "\n",
                "# 2. Accuracy Curve\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(final_history['train_acc'], label='Train Acc', marker='.')\n",
                "plt.plot(final_history['val_acc'], label='Val Acc', marker='.')\n",
                "plt.title('Final Model Training - Accuracy')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "plt.grid(True, linestyle='--')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / \"final_training_history.png\")\n",
                "plt.show()\n",
                "\n",
                "print(f\"ğŸ“ˆ í•™ìŠµ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_DIR / 'final_training_history.png'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [8. ìµœì¢… ê²°ê³¼ ì‹¬ì¸µ ë¶„ì„: ì˜¤ì°¨ í–‰ë ¬ & ì‹¤íŒ¨ ì‚¬ë¡€] ---\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "# 1. Best Model ë¡œë“œ\n",
                "final_model.load_state_dict(torch.load(OUTPUT_DIR / \"final_efficientnet_b0.pth\"))\n",
                "final_model.eval()\n",
                "\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "failed_samples = [] # í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ìš©\n",
                "\n",
                "print(\"ğŸ” ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦ ì¤‘...\")\n",
                "with torch.no_grad():\n",
                "    for imgs, labels in test_loader:\n",
                "        imgs = imgs.to(DEVICE)\n",
                "        outputs = final_model(imgs)\n",
                "        _, preds = torch.max(outputs, 1)\n",
                "        \n",
                "        for i in range(len(preds)):\n",
                "            pred = preds[i].item()\n",
                "            label = labels[i].item()\n",
                "            all_preds.append(pred)\n",
                "            all_labels.append(label)\n",
                "            \n",
                "            if pred != label:\n",
                "                # í‹€ë¦° ê²½ìš°: ì´ë¯¸ì§€(tensor)ë¥¼ cpuë¡œ ì˜®ê²¨ì„œ ì €ì¥\n",
                "                failed_samples.append((imgs[i].cpu(), label, pred))\n",
                "\n",
                "# 2. Confusion Matrix ì‹œê°í™”\n",
                "cm = confusion_matrix(all_labels, all_preds)\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Defect'], yticklabels=['Normal', 'Defect'])\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix (Final Model)')\n",
                "plt.savefig(OUTPUT_DIR / \"final_confusion_matrix.png\")\n",
                "plt.show()\n",
                "\n",
                "print(f\"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½:\")\n",
                "print(f\" - ì „ì²´ ë°ì´í„°: {len(all_labels)}ê°œ\")\n",
                "print(f\" - í‹€ë¦° ê°œìˆ˜: {len(failed_samples)}ê°œ\")\n",
                "print(f\" - ìµœì¢… ì •í™•ë„: {100 * (len(all_labels)-len(failed_samples))/len(all_labels):.2f}%\")\n",
                "\n",
                "# 3. ì‹¤íŒ¨ ì‚¬ë¡€(ì˜¤ë‹µ) ì‹œê°í™” (ìµœëŒ€ 5ê°œ)\n",
                "if len(failed_samples) > 0:\n",
                "    print(\"\\nâŒ ì˜¤ë‹µ ë…¸íŠ¸ (í‹€ë¦° ì¼€ì´ìŠ¤ í™•ì¸)\")\n",
                "    num_show = min(5, len(failed_samples))\n",
                "    fig, axes = plt.subplots(1, num_show, figsize=(15, 3))\n",
                "    if num_show == 1: axes = [axes]\n",
                "    \n",
                "    for i in range(num_show):\n",
                "        img_tensor, true_label, pred_label = failed_samples[i]\n",
                "        # Tensor -> Image ë³€í™˜ (Unnormalize)\n",
                "        img_np = img_tensor.permute(1, 2, 0).numpy()\n",
                "        img_np = img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
                "        img_np = np.clip(img_np, 0, 1)\n",
                "        \n",
                "        axes[i].imshow(img_np)\n",
                "        axes[i].set_title(f\"True: {true_label} | Pred: {pred_label}\", color='red')\n",
                "        axes[i].axis('off')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"ğŸ‰ ì™€ìš°! í‹€ë¦° ë¬¸ì œê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. ì™„ë²½í•©ë‹ˆë‹¤!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}